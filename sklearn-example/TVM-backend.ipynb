{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ddfb8d-6b24-4485-8f9b-19bf5b42e476",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The following operators are not implemented: ['aten::mode']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 使用 Hummingbird 将模型转换为 TVM 格式\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m hb_model \u001b[38;5;241m=\u001b[39m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtvm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 提取 TVM 模块和参数\u001b[39;00m\n\u001b[1;32m     19\u001b[0m tvm_model \u001b[38;5;241m=\u001b[39m hb_model\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/hummingbird/ml/convert.py:444\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(model, backend, test_input, device, extra_config)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03mThis function converts the specified input *model* into an implementation targeting *backend*.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m*Convert* supports [Sklearn], [LightGBM], [XGBoost], [ONNX], and [SparkML] models.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    A model implemented in *backend*, which is equivalent to the input model\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mREMAINDER_SIZE \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m extra_config\n\u001b[0;32m--> 444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_common\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/hummingbird/ml/convert.py:405\u001b[0m, in \u001b[0;36m_convert_common\u001b[0;34m(model, backend, test_input, device, extra_config)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_sparkml_model(model):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_sparkml(model, backend_formatted, test_input, device, extra_config)\n\u001b[0;32m--> 405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_formatted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/hummingbird/ml/convert.py:111\u001b[0m, in \u001b[0;36m_convert_sklearn\u001b[0;34m(model, backend, test_input, device, extra_config)\u001b[0m\n\u001b[1;32m    108\u001b[0m topology \u001b[38;5;241m=\u001b[39m parse_sklearn_api_model(model, extra_config)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Convert the Topology object into a PyTorch model.\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m hb_model \u001b[38;5;241m=\u001b[39m \u001b[43mtopology_converter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hb_model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/hummingbird/ml/_topology.py:323\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(topology, backend, test_input, device, extra_config)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# First we need to generate the torchscript model.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m batch_trace_input, remainder_trace_input \u001b[38;5;241m=\u001b[39m _get_trace_input_from_test_input(test_input, remainder_size, extra_config)\n\u001b[0;32m--> 323\u001b[0m tvm_model \u001b[38;5;241m=\u001b[39m \u001b[43m_compile_to_tvm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_trace_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remainder_trace_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     remainder_model \u001b[38;5;241m=\u001b[39m _compile_to_tvm(topology, executor, remainder_trace_input, target, ctx, config, extra_config)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/hummingbird/ml/_topology.py:163\u001b[0m, in \u001b[0;36m_compile_to_tvm\u001b[0;34m(topology, executor, trace_input, target, ctx, config, extra_config)\u001b[0m\n\u001b[1;32m    154\u001b[0m ts_model \u001b[38;5;241m=\u001b[39m _jit_trace(executor, trace_input, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra_config)\n\u001b[1;32m    155\u001b[0m test_input \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    156\u001b[0m     (\n\u001b[1;32m    157\u001b[0m         topology\u001b[38;5;241m.\u001b[39minput_container\u001b[38;5;241m.\u001b[39minput_names[i],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(topology\u001b[38;5;241m.\u001b[39minput_container\u001b[38;5;241m.\u001b[39minput_names))\n\u001b[1;32m    161\u001b[0m ]\n\u001b[0;32m--> 163\u001b[0m model, params \u001b[38;5;241m=\u001b[39m \u001b[43mrelay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrontend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tvm\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mPassContext(opt_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[1;32m    166\u001b[0m     graph, lib, params \u001b[38;5;241m=\u001b[39m relay\u001b[38;5;241m.\u001b[39mbuild(model, target\u001b[38;5;241m=\u001b[39mtarget, params\u001b[38;5;241m=\u001b[39mparams)\n",
      "File \u001b[0;32m~/project/ONNX-MLIR/tvm/python/tvm/relay/frontend/pytorch.py:5387\u001b[0m, in \u001b[0;36mfrom_pytorch\u001b[0;34m(script_module, input_infos, custom_convert_map, default_dtype, use_parser_friendly_name, keep_quantized_weight, export_renamed_c_graph_path, preserve_pytorch_scopes)\u001b[0m\n\u001b[1;32m   5384\u001b[0m     converter\u001b[38;5;241m.\u001b[39mupdate_convert_map(custom_convert_map)\n\u001b[1;32m   5386\u001b[0m op_names \u001b[38;5;241m=\u001b[39m get_all_op_names(graph)\n\u001b[0;32m-> 5387\u001b[0m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport_missing_conversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5389\u001b[0m is_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(script_module, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule)\n\u001b[1;32m   5390\u001b[0m params \u001b[38;5;241m=\u001b[39m script_module\u001b[38;5;241m.\u001b[39mstate_dict() \u001b[38;5;28;01mif\u001b[39;00m is_module \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "File \u001b[0;32m~/project/ONNX-MLIR/tvm/python/tvm/relay/frontend/pytorch.py:4348\u001b[0m, in \u001b[0;36mPyTorchOpConverter.report_missing_conversion\u001b[0;34m(self, op_names)\u001b[0m\n\u001b[1;32m   4346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m   4347\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following operators are not implemented: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 4348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The following operators are not implemented: ['aten::mode']"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "# 載入 TorchScript 模型\n",
    "ts_model = torch.jit.load('tc_model.pt')\n",
    "\n",
    "# 定義輸入形狀\n",
    "input_shape = (1, 4)\n",
    "shape_list = [('input', input_shape)]\n",
    "\n",
    "# 轉換為 Relay 模型\n",
    "mod, params = relay.frontend.from_pytorch(ts_model, shape_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73268802-821c-4155-99c0-9e78f8ae081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ModelProto' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 提取 TVM 模块和参数\u001b[39;00m\n\u001b[1;32m     20\u001b[0m tvm_model \u001b[38;5;241m=\u001b[39m hb_model\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m---> 21\u001b[0m tvm_mod \u001b[38;5;241m=\u001b[39m \u001b[43mtvm_model\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodule\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     22\u001b[0m tvm_params \u001b[38;5;241m=\u001b[39m tvm_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 构建 Relay 模块并生成共享库\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ModelProto' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from hummingbird.ml import convert\n",
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 训练决策树分类器\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# 使用 Hummingbird 将模型转换为 TVM 格式\n",
    "hb_model = convert(clf, 'onnx', X)\n",
    "\n",
    "# 提取 TVM 模块和参数\n",
    "tvm_model = hb_model.model\n",
    "tvm_mod = tvm_model['module']\n",
    "tvm_params = tvm_model['params']\n",
    "\n",
    "# 构建 Relay 模块并生成共享库\n",
    "target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=x86_64-linux-gnu\")\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(tvm_mod, target=target, params=tvm_params)\n",
    "\n",
    "# 导出编译后的共享库为 .so 文件\n",
    "lib.export_library(\"output.so\", cc=\"x86_64-linux-gnu-gcc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88528122-8878-4582-aa37-38e0f455c589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX 模型已儲存至 tree.onnx\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Model saved with digest: aa9ffdf27a4f8fc05abe252415ddadf62a486dd8\n",
      "Archive:  iris_logistic_regression_torch.zip\n",
      "  inflating: dist/model_type.txt     \n",
      "  inflating: dist/container.pkl      \n",
      "  inflating: dist/model_configuration.txt  \n",
      "  inflating: dist/deploy_model.onnx  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import skl2onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data.astype(np.float32), iris.target\n",
    "\n",
    "# 训练决策树分类器\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# 定義輸入類型\n",
    "initial_type = [('float_input', FloatTensorType([None, X.shape[1]]))]\n",
    "\n",
    "# 轉換為 ONNX 模型\n",
    "onnx_model = convert_sklearn(clf, initial_types=initial_type, target_opset=9)\n",
    "\n",
    "# 指定儲存路徑\n",
    "onnx_file_path = \"tree.onnx\"\n",
    "\n",
    "# 將 ONNX 模型儲存為檔案\n",
    "with open(onnx_file_path, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"ONNX 模型已儲存至 {onnx_file_path}\")\n",
    "\n",
    "from hummingbird.ml import convert\n",
    "\n",
    "# 將 scikit-learn 模型轉換為 ONNX 格式\n",
    "hb_model = convert(onnx_model, 'onnx')\n",
    "\n",
    "# 保存轉換後的 ONNX 模型\n",
    "hb_model.save('iris_logistic_regression_torch')\n",
    "\n",
    "# 解壓縮資料夾\n",
    "!unzip -o iris_logistic_regression_torch.zip -d dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89efcdc-0c1f-4344-8d29-7b8bda8271ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:17:02] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[09:17:02] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[09:17:02] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import cc, utils\n",
    "from tvm.contrib import graph_executor\n",
    "import onnx\n",
    "import sys\n",
    "\n",
    "# original_platform = sys.platform\n",
    "# sys.platform = \"linux\"\n",
    "# 載入 ONNX 模型\n",
    "onnx_model = onnx.load(\"dist/deploy_model.onnx\")\n",
    "\n",
    "# 將 ONNX 模型轉換為 Relay 模型\n",
    "input_name = 'float_input'  # 輸入名稱可在 ONNX 模型中確認\n",
    "shape_dict = {input_name: (1, 4)}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# 設置目標架構，這裡假設為通用的 CPU\n",
    "# target = 'llvm'\n",
    "target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=x86_64-linux-gnu\")\n",
    "# target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "# target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=x86_64-apple-darwin\")\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n",
    "\n",
    "# 編譯輸出為 C 代碼\n",
    "lib.export_library(\"output.so\", cc=\"x86_64-linux-gnu-gcc\")\n",
    "# lib.export_library(\"output.so\", cc=\"aarch64-linux-gnu-gcc\")\n",
    "# lib.export_library(\"output.so\", cc=\"clang\")\n",
    "\n",
    "# 恢復原始平台\n",
    "# sys.platform = original_platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250289ce-8916-4354-b7c1-0f260c05cde2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=x86_64-linux-gnu\")\n",
    "# target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "# target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=x86_64-apple-darwin\")\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbda7c-ff14-469f-a2bd-69b5bee55e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
