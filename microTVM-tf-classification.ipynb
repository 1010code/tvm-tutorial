{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e3b12d-ecf7-4995-9a24-50d9c0177b7e",
   "metadata": {},
   "source": [
    "## 1. 建立並保存 ONNX 模型檔案\n",
    "以下是一個使用 TensorFlow 建立鳶尾花（Iris）分類模型並將其導出為 ONNX 格式的範例。該模型使用簡單的全連接層來進行分類，並轉換為 ONNX 格式，方便在 TVM 或其他 ONNX 支持的推理引擎上運行。\n",
    "\n",
    "### 1.1 安裝必要的套件\n",
    "如果尚未安裝 tensorflow 和 tf2onnx，可以使用以下命令安裝：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277e745-0d29-4070-9a60-a5d4b1976ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow tf2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba6d0b-54b1-4aac-bc67-2981917f4e77",
   "metadata": {},
   "source": [
    "### 1.2 建立並訓練 TensorFlow 模型\n",
    "以下程式碼將建立一個簡單的神經網絡來分類鳶尾花數據集，並將其導出為 ONNX 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc99edeb-2521-497d-a7b3-568f78658725",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 11:47:00.357040: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 11:47:00.397227: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-13 11:47:00.397246: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-13 11:47:00.397274: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-13 11:47:00.404958: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 11:47:00.405555: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-13 11:47:01.387785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-13 11:47:02.634403: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型準確率: 1.00\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 載入鳶尾花資料集\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "y = iris.target\n",
    "\n",
    "# 分割資料集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 建立模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(4,)),  # 4 個特徵\n",
    "    tf.keras.layers.Dense(10, activation='relu'),  # 隱藏層\n",
    "    tf.keras.layers.Dense(3, activation='softmax') # 輸出層，3 個分類\n",
    "])\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=5, verbose=0)\n",
    "\n",
    "# 評估模型\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"模型準確率: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed8f4e0-2f4e-45c0-8084-2d4a103ce2bf",
   "metadata": {},
   "source": [
    "### 1.3 將模型轉換為 ONNX 格式\n",
    "使用 tf2onnx 將訓練好的 TensorFlow 模型轉換為 ONNX 格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4db139-3d34-41df-a060-0f60f28a628f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:30:12.466954: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 16:30:12.504919: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-13 16:30:12.504939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-13 16:30:12.504963: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-13 16:30:12.512059: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 16:30:12.512504: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-13 16:30:13.297280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf2onnx\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 將 Keras 模型轉換為 ONNX 格式\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m spec \u001b[38;5;241m=\u001b[39m (\u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mTensorSpec((\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m4\u001b[39m), tf\u001b[38;5;241m.\u001b[39mfloat32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat_input\u001b[39m\u001b[38;5;124m\"\u001b[39m),)  \u001b[38;5;66;03m# 定義輸入規範\u001b[39;00m\n\u001b[1;32m      5\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_model.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 輸出 ONNX 模型的路徑\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 轉換模型\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "import tf2onnx\n",
    "\n",
    "# 將 Keras 模型轉換為 ONNX 格式\n",
    "spec = (tf.TensorSpec((None, 4), tf.float32, name=\"float_input\"),)  # 定義輸入規範\n",
    "output_path = \"tf_model.onnx\"  # 輸出 ONNX 模型的路徑\n",
    "\n",
    "# 轉換模型\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n",
    "\n",
    "print(f\"ONNX 模型已保存至 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1187866b-1998-429a-8ed3-d7c7a09dac36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[5.2434858e-04, 8.7534554e-02, 9.1194111e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# 加載 ONNX 模型\n",
    "session = ort.InferenceSession('tf_model.onnx')\n",
    "\n",
    "# 準備輸入資料\n",
    "input_name = session.get_inputs()[0].name\n",
    "input_data = np.array([[6.3, 3.3, 6.0, 2.5]], dtype=np.float32)\n",
    "\n",
    "# 進行推理\n",
    "pred_onnx = session.run(None, {input_name: input_data})\n",
    "\n",
    "# 輸出預測結果\n",
    "print(pred_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42448fdf-4d70-4447-b0bc-814ccdc19abd",
   "metadata": {},
   "source": [
    "## 2. TVM 進行編譯產生 C\n",
    "### 2.1 轉換模型為 Relay 格式\n",
    "在 TVM 中，我們可以使用 ONNX 格式轉換模型，然後導入 TVM 中。如果使用者已有其他框架的模型（如 TensorFlow、Keras、PyTorch），可相應轉換為 Relay 支持的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b04525-8651-4e29-9294-8e4cdac03c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export TVM_HOME=/home/jovyan/project/ONNX-MLIR/tvm\n",
    "!export PYTHONPATH=$TVM_HOME/python:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b34bd9-7fb7-4727-ae50-de0e0d427ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!TVM_LIBRARY_PATH=/home/jovyan/project/ONNX-MLIR/tvm/build python3 run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f423c6e-3151-4964-85d1-bed990f71884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:52:22] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[20:52:22] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[20:52:22] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/project/ONNX-MLIR/tvm/python/tvm/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "print(tvm.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e9ceab-dc38-4943-994a-d9f1aa7a3373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:28:34] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[17:28:34] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[17:28:34] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "/home/jovyan/project/ONNX-MLIR/tvm/python/tvm/__init__.py\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tvm; print(tvm.__file__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d517ed-9ccd-4646-800c-22f341fea275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import skl2onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "\n",
    "# 導入 ONNX 模型至 TVM Relay\n",
    "import tvm.relay as relay\n",
    "\n",
    "onnx_model = onnx.load(\"tf_model.onnx\")\n",
    "shape_dict = {\"float_input\": (1, 4)}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84effb3-c0d8-41d0-9049-45d62383a453",
   "metadata": {},
   "source": [
    "###  2.2 設置 microTVM 和生成 C 代碼\n",
    "使用 microTVM 的 AOT（Ahead-of-Time）執行器來生成適合嵌入式設備的 C 代碼。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "513b673a-509b-4424-ac88-03f2d032785d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:29:40] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[17:29:40] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[17:29:40] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/project/ONNX-MLIR/tvm-tutorial/run.py\", line 23, in <module>\n",
      "    lowered_module.get_lib().export_library(\"iris_model.c\", tvm.micro.export_model_library_format)\n",
      "AttributeError: module 'tvm' has no attribute 'micro'\n"
     ]
    }
   ],
   "source": [
    "!TVM_LIBRARY_PATH=/home/jovyan/project/ONNX-MLIR/tvm/build python3 run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab42b35f-9f0c-4f03-8bbb-fb79f4b7d008",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Compilation error:\n/tmp/tmp5y2hzsyt/lib0.c: In function ‘int32_t tvmgen_default_fused_nn_contrib_dense_pack_add(void*, int32_t*, int32_t, void*, int32_t*, void*)’:\n/tmp/tmp5y2hzsyt/lib0.c:95:3: error: ‘float3’ was not declared in this scope; did you mean ‘float’?\n   95 |   float3 compute_global[1];\n      |   ^~~~~~\n      |   float\n/tmp/tmp5y2hzsyt/lib0.c:96:3: error: ‘compute_global’ was not declared in this scope\n   96 |   compute_global[0] = ((float3)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n      |   ^~~~~~~~~~~~~~\n/tmp/tmp5y2hzsyt/lib0.c:98:144: error: expected primary-expression before ‘)’ token\n   98 |     compute_global[0] = (compute_global[0] + (((float3)(((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer])) * *(float3*)(((float*)fused_constant_1) + (k_outer * 3))));\n      |                                                                                                                                                ^\n/tmp/tmp5y2hzsyt/lib0.c:100:12: error: expected primary-expression before ‘)’ token\n  100 |   *(float3*)(((float*)T_add_1) + 0) = (compute_global[0] + *(float3*)(((float*)fused_nn_contrib_dense_pack_constant_1) + 0));\n      |            ^\n/tmp/tmp5y2hzsyt/lib0.c:100:69: error: expected primary-expression before ‘)’ token\n  100 |   *(float3*)(((float*)T_add_1) + 0) = (compute_global[0] + *(float3*)(((float*)fused_nn_contrib_dense_pack_constant_1) + 0));\n      |                                                                     ^\n/tmp/tmp5y2hzsyt/lib0.c: In function ‘int32_t tvmgen_default_fused_nn_contrib_dense_pack_add_nn_relu(void*, int32_t*, int32_t, void*, int32_t*, void*)’:\n/tmp/tmp5y2hzsyt/lib0.c:125:5: error: ‘float5’ was not declared in this scope; did you mean ‘float’?\n  125 |     float5 compute_global[1];\n      |     ^~~~~~\n      |     float\n/tmp/tmp5y2hzsyt/lib0.c:126:5: error: ‘compute_global’ was not declared in this scope\n  126 |     compute_global[0] = ((float5)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n      |     ^~~~~~~~~~~~~~\n/tmp/tmp5y2hzsyt/lib0.c:128:196: error: expected primary-expression before ‘)’ token\n  128 |       compute_global[0] = (compute_global[0] + (((float5)(((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer])) * *(float5*)(((float*)fused_constant) + ((ax1_outer_ax0_outer_fused * 20) + (k_outer * 5)))));\n      |                                                                                                                                                                                                    ^\n/tmp/tmp5y2hzsyt/lib0.c:130:5: error: ‘int32_t5’ was not declared in this scope; did you mean ‘int32_t’?\n  130 |     int32_t5 v_ = int32_t5((cse_var_1)+(1*0), (cse_var_1)+(1*1), (cse_var_1)+(1*2), (cse_var_1)+(1*3), (cse_var_1)+(1*4));\n      |     ^~~~~~~~\n      |     int32_t\n/tmp/tmp5y2hzsyt/lib0.c:131:11: error: expected ‘;’ before ‘v__1’\n  131 |     float5 v__1 = compute_global[0] + (float5(((float*)fused_nn_contrib_dense_pack_constant)[v_.s0],((float*)fused_nn_contrib_dense_pack_constant)[v_.s1],((float*)fused_nn_contrib_dense_pack_constant)[v_.s2],((float*)fused_nn_contrib_dense_pack_constant)[v_.s3],((float*)fused_nn_contrib_dense_pack_constant)[v_.s4]));\n      |           ^~~~~\n      |           ;\n/tmp/tmp5y2hzsyt/lib0.c:132:11: error: expected ‘;’ before ‘v__2’\n  132 |     float5 v__2 = (float5)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f);\n      |           ^~~~~\n      |           ;\n/tmp/tmp5y2hzsyt/lib0.c:133:14: error: expected primary-expression before ‘)’ token\n  133 |     *(float5*)(((float*)T_relu_1) + cse_var_1) = ((v__1) > (v__2) ? (v__1) : (v__2));\n      |              ^\n/tmp/tmp5y2hzsyt/lib0.c:133:52: error: ‘v__1’ was not declared in this scope\n  133 |     *(float5*)(((float*)T_relu_1) + cse_var_1) = ((v__1) > (v__2) ? (v__1) : (v__2));\n      |                                                    ^~~~\n/tmp/tmp5y2hzsyt/lib0.c:133:61: error: ‘v__2’ was not declared in this scope\n  133 |     *(float5*)(((float*)T_relu_1) + cse_var_1) = ((v__1) > (v__2) ? (v__1) : (v__2));\n      |                                                             ^~~~\n\nCommand line: /usr/bin/g++ -shared -fPIC -o iris_model.c /tmp/tmp5y2hzsyt/lib0.c /tmp/tmp5y2hzsyt/lib1.c /tmp/tmp5y2hzsyt/devc.o -I/home/jovyan/project/ONNX-MLIR/tvm/include -I/home/jovyan/project/ONNX-MLIR/tvm/3rdparty/dlpack/include -I/home/jovyan/project/ONNX-MLIR/tvm/3rdparty/dmlc-core/include",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     lowered_module \u001b[38;5;241m=\u001b[39m relay\u001b[38;5;241m.\u001b[39mbuild(mod, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m, params\u001b[38;5;241m=\u001b[39mparams, executor\u001b[38;5;241m=\u001b[39mtvm\u001b[38;5;241m.\u001b[39mrelay\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mExecutor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 將生成的模型保存為 C 源碼\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mlowered_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_library\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miris_model.c\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/ONNX-MLIR/tvm/python/tvm/runtime/module.py:628\u001b[0m, in \u001b[0;36mModule.export_library\u001b[0;34m(self, file_name, fcompile, fpack_imports, addons, workspace_dir, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     opts \u001b[38;5;241m=\u001b[39m options \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-I\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m path \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m find_include_path()]\n\u001b[1;32m    626\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: opts})\n\u001b[0;32m--> 628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/ONNX-MLIR/tvm/python/tvm/contrib/cc.py:94\u001b[0m, in \u001b[0;36mcreate_shared\u001b[0;34m(output, objects, options, cc, cwd, ccache_env)\u001b[0m\n\u001b[1;32m     91\u001b[0m cc \u001b[38;5;241m=\u001b[39m cc \u001b[38;5;129;01mor\u001b[39;00m get_cc()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_linux_like():\n\u001b[0;32m---> 94\u001b[0m     \u001b[43m_linux_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mccache_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_shared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_windows_like():\n\u001b[1;32m     96\u001b[0m     _windows_compile(output, objects, options, cwd, ccache_env)\n",
      "File \u001b[0;32m~/project/ONNX-MLIR/tvm/python/tvm/contrib/cc.py:371\u001b[0m, in \u001b[0;36m_linux_compile\u001b[0;34m(output, objects, options, compile_cmd, cwd, ccache_env, compile_shared)\u001b[0m\n\u001b[1;32m    369\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m py_str(out)\n\u001b[1;32m    370\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCommand line: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd)\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Compilation error:\n/tmp/tmp5y2hzsyt/lib0.c: In function ‘int32_t tvmgen_default_fused_nn_contrib_dense_pack_add(void*, int32_t*, int32_t, void*, int32_t*, void*)’:\n/tmp/tmp5y2hzsyt/lib0.c:95:3: error: ‘float3’ was not declared in this scope; did you mean ‘float’?\n   95 |   float3 compute_global[1];\n      |   ^~~~~~\n      |   float\n/tmp/tmp5y2hzsyt/lib0.c:96:3: error: ‘compute_global’ was not declared in this scope\n   96 |   compute_global[0] = ((float3)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n      |   ^~~~~~~~~~~~~~\n/tmp/tmp5y2hzsyt/lib0.c:98:144: error: expected primary-expression before ‘)’ token\n   98 |     compute_global[0] = (compute_global[0] + (((float3)(((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer])) * *(float3*)(((float*)fused_constant_1) + (k_outer * 3))));\n      |                                                                                                                                                ^\n/tmp/tmp5y2hzsyt/lib0.c:100:12: error: expected primary-expression before ‘)’ token\n  100 |   *(float3*)(((float*)T_add_1) + 0) = (compute_global[0] + *(float3*)(((float*)fused_nn_contrib_dense_pack_constant_1) + 0));\n      |            ^\n/tmp/tmp5y2hzsyt/lib0.c:100:69: error: expected primary-expression before ‘)’ token\n  100 |   *(float3*)(((float*)T_add_1) + 0) = (compute_global[0] + *(float3*)(((float*)fused_nn_contrib_dense_pack_constant_1) + 0));\n      |                                                                     ^\n/tmp/tmp5y2hzsyt/lib0.c: In function ‘int32_t tvmgen_default_fused_nn_contrib_dense_pack_add_nn_relu(void*, int32_t*, int32_t, void*, int32_t*, void*)’:\n/tmp/tmp5y2hzsyt/lib0.c:125:5: error: ‘float5’ was not declared in this scope; did you mean ‘float’?\n  125 |     float5 compute_global[1];\n      |     ^~~~~~\n      |     float\n/tmp/tmp5y2hzsyt/lib0.c:126:5: error: ‘compute_global’ was not declared in this scope\n  126 |     compute_global[0] = ((float5)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n      |     ^~~~~~~~~~~~~~\n/tmp/tmp5y2hzsyt/lib0.c:128:196: error: expected primary-expression before ‘)’ token\n  128 |       compute_global[0] = (compute_global[0] + (((float5)(((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer], ((float*)p0_1)[k_outer])) * *(float5*)(((float*)fused_constant) + ((ax1_outer_ax0_outer_fused * 20) + (k_outer * 5)))));\n      |                                                                                                                                                                                                    ^\n/tmp/tmp5y2hzsyt/lib0.c:130:5: error: ‘int32_t5’ was not declared in this scope; did you mean ‘int32_t’?\n  130 |     int32_t5 v_ = int32_t5((cse_var_1)+(1*0), (cse_var_1)+(1*1), (cse_var_1)+(1*2), (cse_var_1)+(1*3), (cse_var_1)+(1*4));\n      |     ^~~~~~~~\n      |     int32_t\n/tmp/tmp5y2hzsyt/lib0.c:131:11: error: expected ‘;’ before ‘v__1’\n  131 |     float5 v__1 = compute_global[0] + (float5(((float*)fused_nn_contrib_dense_pack_constant)[v_.s0],((float*)fused_nn_contrib_dense_pack_constant)[v_.s1],((float*)fused_nn_contrib_dense_pack_constant)[v_.s2],((float*)fused_nn_contrib_dense_pack_constant)[v_.s3],((float*)fused_nn_contrib_dense_pack_constant)[v_.s4]));\n      |           ^~~~~\n      |           ;\n/tmp/tmp5y2hzsyt/lib0.c:132:11: error: expected ‘;’ before ‘v__2’\n  132 |     float5 v__2 = (float5)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f);\n      |           ^~~~~\n      |           ;\n/tmp/tmp5y2hzsyt/lib0.c:133:14: error: expected primary-expression before ‘)’ token\n  133 |     *(float5*)(((float*)T_relu_1) + cse_var_1) = ((v__1) > (v__2) ? (v__1) : (v__2));\n      |              ^\n/tmp/tmp5y2hzsyt/lib0.c:133:52: error: ‘v__1’ was not declared in this scope\n  133 |     *(float5*)(((float*)T_relu_1) + cse_var_1) = ((v__1) > (v__2) ? (v__1) : (v__2));\n      |                                                    ^~~~\n/tmp/tmp5y2hzsyt/lib0.c:133:61: error: ‘v__2’ was not declared in this scope\n  133 |     *(float5*)(((float*)T_relu_1) + cse_var_1) = ((v__1) > (v__2) ? (v__1) : (v__2));\n      |                                                             ^~~~\n\nCommand line: /usr/bin/g++ -shared -fPIC -o iris_model.c /tmp/tmp5y2hzsyt/lib0.c /tmp/tmp5y2hzsyt/lib1.c /tmp/tmp5y2hzsyt/devc.o -I/home/jovyan/project/ONNX-MLIR/tvm/include -I/home/jovyan/project/ONNX-MLIR/tvm/3rdparty/dlpack/include -I/home/jovyan/project/ONNX-MLIR/tvm/3rdparty/dmlc-core/include"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "# from tvm import relay\n",
    "# import tvm.micro\n",
    "\n",
    "# 定義目標硬體平台 (這裡以 `c` 為主，代表原生 C 代碼)\n",
    "target = tvm.target.target.micro(\"host\")\n",
    "\n",
    "# 設定編譯選項\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lowered_module = relay.build(mod, target='c', params=params, executor=tvm.relay.backend.Executor(\"aot\"))\n",
    "\n",
    "# 將生成的模型保存為 C 源碼\n",
    "lowered_module.get_lib().export_library(\"iris_model.c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e295530-b09a-4fb3-8a35-1c2ce9be327b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fef650d-4171-4c74-aaf0-54e16d46bd3f",
   "metadata": {},
   "source": [
    "## microTVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db22d8c-54d3-4500-9144-4250bcfcbaea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import utils\n",
    "from tvm.relay.backend import Runtime\n",
    "import onnx\n",
    "\n",
    "# 載入 ONNX 模型\n",
    "onnx_model = onnx.load(\"tf_model.onnx\")\n",
    "\n",
    "# 將 ONNX 模型轉換為 Relay 模型\n",
    "input_name = 'float_input'  # 輸入名稱依據您的 ONNX 模型\n",
    "shape_dict = {input_name: (1, 4)}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# 設置目標架構並啟用 C runtime\n",
    "target = tvm.target.Target(\"llvm -system-lib -mtriple=x86_64-linux-gnu\")\n",
    "runtime = Runtime(\"c\")\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    # 編譯模型，指定 runtime=runtime 並啟用 system-lib\n",
    "    lib = relay.build(mod, target=target, params=params, runtime=runtime)\n",
    "\n",
    "# 將 C 代碼導出為 model.c\n",
    "lib.export_library(\"model.c\", cc=\"gcc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4c143-965f-4b02-a7e0-964bce3db382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36445887-588c-4332-b609-8c621fb10841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xvf ./module.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a543d42-711a-414c-89ce-cba1cd6a7b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
