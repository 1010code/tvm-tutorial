{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e3b12d-ecf7-4995-9a24-50d9c0177b7e",
   "metadata": {},
   "source": [
    "## 1. 建立並保存 ONNX 模型檔案\n",
    "以下是一個使用 TensorFlow 建立鳶尾花（Iris）分類模型並將其導出為 ONNX 格式的範例。該模型使用簡單的全連接層來進行分類，並轉換為 ONNX 格式，方便在 TVM 或其他 ONNX 支持的推理引擎上運行。\n",
    "\n",
    "### 1.1 安裝必要的套件\n",
    "如果尚未安裝 tensorflow 和 tf2onnx，可以使用以下命令安裝：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277e745-0d29-4070-9a60-a5d4b1976ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow tf2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba6d0b-54b1-4aac-bc67-2981917f4e77",
   "metadata": {},
   "source": [
    "### 1.2 建立並訓練 TensorFlow 模型\n",
    "以下程式碼將建立一個簡單的神經網絡來分類鳶尾花數據集，並將其導出為 ONNX 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc99edeb-2521-497d-a7b3-568f78658725",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 22:38:20.798397: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 22:38:20.839582: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-13 22:38:20.839610: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-13 22:38:20.839650: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-13 22:38:20.848293: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 22:38:20.849394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-13 22:38:21.699022: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-13 22:38:22.950154: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型準確率: 0.97\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 載入鳶尾花資料集\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "y = iris.target\n",
    "\n",
    "# 分割資料集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 建立模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(4,)),  # 4 個特徵\n",
    "    tf.keras.layers.Dense(10, activation='relu'),  # 隱藏層\n",
    "    tf.keras.layers.Dense(3, activation='softmax') # 輸出層，3 個分類\n",
    "])\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=5, verbose=0)\n",
    "\n",
    "# 評估模型\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"模型準確率: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed8f4e0-2f4e-45c0-8084-2d4a103ce2bf",
   "metadata": {},
   "source": [
    "### 1.3 將模型轉換為 ONNX 格式\n",
    "使用 tf2onnx 將訓練好的 TensorFlow 模型轉換為 ONNX 格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4db139-3d34-41df-a060-0f60f28a628f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "\n",
    "# 將 Keras 模型轉換為 ONNX 格式\n",
    "spec = (tf.TensorSpec((None, 4), tf.float32, name=\"float_input\"),)  # 定義輸入規範\n",
    "output_path = \"tf_model.onnx\"  # 輸出 ONNX 模型的路徑\n",
    "\n",
    "# 轉換模型\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n",
    "\n",
    "print(f\"ONNX 模型已保存至 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1187866b-1998-429a-8ed3-d7c7a09dac36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[5.2434858e-04, 8.7534554e-02, 9.1194111e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# 加載 ONNX 模型\n",
    "session = ort.InferenceSession('tf_model.onnx')\n",
    "\n",
    "# 準備輸入資料\n",
    "input_name = session.get_inputs()[0].name\n",
    "input_data = np.array([[6.3, 3.3, 6.0, 2.5]], dtype=np.float32)\n",
    "\n",
    "# 進行推理\n",
    "pred_onnx = session.run(None, {input_name: input_data})\n",
    "\n",
    "# 輸出預測結果\n",
    "print(pred_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42448fdf-4d70-4447-b0bc-814ccdc19abd",
   "metadata": {},
   "source": [
    "## 2. TVM 進行編譯產生 C\n",
    "### 2.1 轉換模型為 Relay 格式\n",
    "在 TVM 中，我們可以使用 ONNX 格式轉換模型，然後導入 TVM 中。如果使用者已有其他框架的模型（如 TensorFlow、Keras、PyTorch），可相應轉換為 Relay 支持的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b04525-8651-4e29-9294-8e4cdac03c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export TVM_HOME=/home/jovyan/project/ONNX-MLIR/tvm\n",
    "!export PYTHONPATH=$TVM_HOME/python:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b34bd9-7fb7-4727-ae50-de0e0d427ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!TVM_LIBRARY_PATH=/home/jovyan/project/ONNX-MLIR/tvm/build python3 run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f423c6e-3151-4964-85d1-bed990f71884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/project/ONNX-MLIR/tvm/python/tvm/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "print(tvm.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98e9ceab-dc38-4943-994a-d9f1aa7a3373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:38:39] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[22:38:39] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[22:38:39] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "/home/jovyan/project/ONNX-MLIR/tvm/python/tvm/__init__.py\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tvm; print(tvm.__file__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4d517ed-9ccd-4646-800c-22f341fea275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "# 加载 ONNX 模型\n",
    "onnx_model = onnx.load(\"tf_model.onnx\")\n",
    "\n",
    "# 定义输入形状（根据您的模型调整）\n",
    "shape_dict = {\"float_input\": (1, 4)}  # 请替换为您的实际输入名和形状\n",
    "\n",
    "# 将 ONNX 模型转换为 Relay IR\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "752f82da-3177-4ba5-ad5a-844f388410f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置目标为生成 C 代码\n",
    "target = tvm.target.Target(\"c\")\n",
    "\n",
    "# 设置运行时为 'crt' 并启用 'system-lib' 选项\n",
    "runtime = tvm.relay.backend.Runtime(\"crt\", {\"system-lib\": True})\n",
    "\n",
    "# 配置 AOT 执行器\n",
    "executor = relay.build_module.Executor(\"aot\", {\n",
    "    \"interface-api\": \"c\",\n",
    "    \"unpacked-api\": True,\n",
    "})\n",
    "\n",
    "# 编译模块\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params, runtime=runtime, executor=executor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a8adae8-6a17-46a8-bddd-1c1932e9fe16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取生成的 C 代码\n",
    "c_source = lib.lib.get_source()\n",
    "\n",
    "# 保存 C 代码到文件\n",
    "with open(\"model.c\", \"w\") as f:\n",
    "    f.write(c_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee113911-a6d9-42e5-bfeb-c4dc087cd91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e5a888f-41a9-4f62-9b1b-dd7dde00acf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "# 加载 ONNX 模型\n",
    "onnx_model = onnx.load(\"tf_model.onnx\")\n",
    "shape_dict = {\"float_input\": (1, 4)}  # 根据您的模型输入调整形状\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "from tvm.relay.backend import Executor, Runtime\n",
    "\n",
    "# 设置目标为 C，并启用 system-lib\n",
    "target = tvm.target.Target(\"c\")\n",
    "\n",
    "\n",
    "# 配置执行器为 AOT，接口 API 为 C，使用 unpacked API\n",
    "executor = Executor(\"aot\", {\"interface-api\": \"c\", \"unpacked-api\": True})\n",
    "\n",
    "# 设置运行时为 C 运行时，并启用 system-lib\n",
    "runtime = Runtime(\"crt\", {\"system-lib\": True})\n",
    "from tvm.contrib import utils\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params, executor=executor, runtime=runtime)\n",
    "# 导出生成的 C 代码\n",
    "temp = utils.tempdir()\n",
    "lib.export_library(temp.relpath(\"deploy.tar\"))\n",
    "\n",
    "# 解压生成的代码\n",
    "import tarfile\n",
    "tar = tarfile.open(temp.relpath(\"deploy.tar\"))\n",
    "tar.extractall(temp.relpath(\"./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c40e5da5-4b93-4c7d-af3a-a2380408df52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpn17sro6c/deploy.tar'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.relpath(\"deploy.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2aefc516-915f-4d4e-b114-c49670611f95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy.tar  devc.c  lib0.c  lib1.c\n"
     ]
    }
   ],
   "source": [
    "!ls '/tmp/tmpn17sro6c/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6b88340-e5ed-4e14-b699-a82eec31b8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lib1.c\n",
      "devc.c\n",
      "lib0.c\n"
     ]
    }
   ],
   "source": [
    "!tar xvf ./test/model.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "914d2e86-0463-4024-80b7-a207b158036a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[Kmodel.c:72:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Ktvmgen_default.h: No such file or directory\n",
      "   72 | #include \u001b[01;31m\u001b[K<tvmgen_default.h>\u001b[m\u001b[K\n",
      "      |          \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "compilation terminated.\n",
      "\u001b[01m\u001b[Kmain.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmain\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kmain.c:17:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kimplicit declaration of function ‘\u001b[01m\u001b[Kmodel\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wimplicit-function-declaration\u0007-Wimplicit-function-declaration\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   17 |     \u001b[01;35m\u001b[Kmodel\u001b[m\u001b[K(input_data, output_data);\n",
      "      |     \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "# !gcc -o model_exec main.c model.c -I../tvm/include -I../tvm/3rdparty/dlpack/include -I../tvm/3rdparty/dmlc-core/include\n",
    "!gcc -O2 -o model_exec model.c main.c -I../tvm/3rdparty/dlpack/include\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84effb3-c0d8-41d0-9049-45d62383a453",
   "metadata": {},
   "source": [
    "###  2.2 設置 microTVM 和生成 C 代碼\n",
    "使用 microTVM 的 AOT（Ahead-of-Time）執行器來生成適合嵌入式設備的 C 代碼。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513b673a-509b-4424-ac88-03f2d032785d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:01:22] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[22:01:22] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "[22:01:22] /home/jovyan/project/ONNX-MLIR/tvm/src/target/llvm/llvm_instance.cc:226: Error: Using LLVM 19.1.3 with `-mcpu=apple-latest` is not valid in `-mtriple=arm64-apple-macos`, using default `-mcpu=generic`\n",
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/project/ONNX-MLIR/tvm-tutorial/run.py\", line 23, in <module>\n",
      "    lowered_module.get_lib().export_library(\"iris_model.c\", tvm.micro.export_model_library_format)\n",
      "TypeError: export_library() takes 2 positional arguments but 3 were given\n"
     ]
    }
   ],
   "source": [
    "!TVM_LIBRARY_PATH=/home/jovyan/project/ONNX-MLIR/tvm/build python3 run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab42b35f-9f0c-4f03-8bbb-fb79f4b7d008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = tvm.target.Target(\"llvm\", host=\"llvm\")\n",
    "executor = relay.build_module.Executor(\"aot\", {\n",
    "    \"interface-api\": \"c\",       # 使用 C 接口\n",
    "    \"unpacked-api\": True        # 使用 unpacked API，减少对运行时的依赖\n",
    "})\n",
    "runtime = tvm.relay.backend.Runtime(\"crt\", {\"system-lib\": True})  # 指定使用 C 运行时\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a543d42-711a-414c-89ce-cba1cd6a7b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
