{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63b3747-72b6-4bf8-9c8d-04c4f2048416",
   "metadata": {},
   "source": [
    "## 1. 建立並保存 ONNX 模型檔案\n",
    "以下是一個使用 TensorFlow 建立鳶尾花（Iris）分類模型並將其導出為 ONNX 格式的範例。該模型使用簡單的全連接層來進行分類，並轉換為 ONNX 格式，方便在 TVM 或其他 ONNX 支持的推理引擎上運行。\n",
    "\n",
    "### 1.1 安裝必要的套件\n",
    "如果尚未安裝 tensorflow 和 tf2onnx，可以使用以下命令安裝：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05157835-f3d5-480a-856f-93fd26ee5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tf2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b324bcc-0e66-42d6-b257-e8e0ce348a3d",
   "metadata": {},
   "source": [
    "### 1.2 建立並訓練 TensorFlow 模型\n",
    "以下程式碼將建立一個簡單的神經網絡來分類鳶尾花數據集，並將其導出為 ONNX 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd84ee2-7aee-4430-9ee3-3dbbc6e4de21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 20:53:47.762606: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-12 20:53:47.800341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-12 20:53:47.800359: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-12 20:53:47.800385: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-12 20:53:47.807329: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-12 20:53:47.807845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-12 20:53:48.653800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-12 20:53:49.981909: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型準確率: 0.87\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 載入鳶尾花資料集\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "y = iris.target\n",
    "\n",
    "# 分割資料集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 建立模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(4,)),  # 4 個特徵\n",
    "    tf.keras.layers.Dense(10, activation='relu'),  # 隱藏層\n",
    "    tf.keras.layers.Dense(3, activation='softmax') # 輸出層，3 個分類\n",
    "])\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=5, verbose=0)\n",
    "\n",
    "# 評估模型\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"模型準確率: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0cad5-688d-4fba-80ff-f7a525da99af",
   "metadata": {},
   "source": [
    "### 1.3 將模型轉換為 ONNX 格式\n",
    "使用 tf2onnx 將訓練好的 TensorFlow 模型轉換為 ONNX 格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4a1d42-a483-45b0-9bbd-d875f8e7facb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX 模型已保存至 tf_model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 20:54:01.888828: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-11-12 20:54:01.888952: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-11-12 20:54:01.911409: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-11-12 20:54:01.911518: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "import tf2onnx\n",
    "\n",
    "# 將 Keras 模型轉換為 ONNX 格式\n",
    "spec = (tf.TensorSpec((None, 4), tf.float32, name=\"float_input\"),)  # 定義輸入規範\n",
    "output_path = \"tf_model.onnx\"  # 輸出 ONNX 模型的路徑\n",
    "\n",
    "# 轉換模型\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n",
    "\n",
    "print(f\"ONNX 模型已保存至 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656f729a-3072-4e1b-9f98-404497970e50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[6.0250495e-05, 2.8771785e-01, 7.1222192e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# 加載 ONNX 模型\n",
    "session = ort.InferenceSession('tf_model.onnx')\n",
    "\n",
    "# 準備輸入資料\n",
    "input_name = session.get_inputs()[0].name\n",
    "input_data = np.array([[6.3, 3.3, 6.0, 2.5]], dtype=np.float32)\n",
    "\n",
    "# 進行推理\n",
    "pred_onnx = session.run(None, {input_name: input_data})\n",
    "\n",
    "# 輸出預測結果\n",
    "print(pred_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50733c-bebe-40ed-a409-8b0df7c64b05",
   "metadata": {},
   "source": [
    "**環境設定與依賴安裝**\n",
    "   - 在開發機器上安裝 TVM。\n",
    "   - 在目標設備（aarch64）上安裝 TVM runtime。\n",
    "   - 確保兩台設備在同一網絡下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82b485-5f5b-4e31-b86e-f55909813fa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. 模型匯入與轉換\n",
    "將模型從原始格式（TensorFlow、PyTorch、ONNX）匯入並轉換為 TVM 的 Relay 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df01e87a-b7e8-4b8f-93eb-17794b40c7fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import rpc, relay\n",
    "from tvm.contrib import utils\n",
    "import onnx\n",
    "\n",
    "# 載入 ONNX 模型\n",
    "onnx_model = onnx.load(\"tf_model.onnx\")\n",
    "\n",
    "# 將 ONNX 模型轉換為 Relay 模型\n",
    "input_name = 'float_input'  # 輸入名稱可在 ONNX 模型中確認\n",
    "shape_dict = {input_name: (1, 4)}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99060f0a-d74f-4ca0-b5ff-164002cd83a4",
   "metadata": {},
   "source": [
    "## 3. 設定編譯目標並編譯模型\n",
    "- 在開發機器上編譯模型，設定目標為 `\"llvm -mtriple=aarch64-linux-gnu\"`。\n",
    "- 使用 TVM 自動調優進行性能優化（選擇性）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2148f365-5d2e-4337-954c-835b2b60583c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "# 在開發機器上編譯模型（例如為 aarch64 設備）\n",
    "target = \"llvm\"\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc6db5-a7e5-4e80-a1f4-2599d04b7884",
   "metadata": {},
   "source": [
    "## 4. 在目標設備上啟動 RPC Server\n",
    "在目標設備上運行 RPC Server，這允許開發機器通過 RPC 連接到目標設備並進行測試。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f80834-3834-4768-87b0-b9e7d46c11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m tvm.exec.rpc_server --host 0.0.0.0 --port=9090\n",
    "# !ngrok tcp 0.0.0.0:9090"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921de69e-6b25-4fe7-8373-98ee5abb81e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. 模型部署與傳輸\n",
    "- 將編譯後生成的二進制文件（例如 .tar 文件或 .so 文件）打包並傳輸到目標設備。\n",
    "- 可以使用 TVM 的 RPC 機制來上傳文件，或手動傳輸文件到目標設備的指定目錄。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05cbcb1c-b44c-4cc5-9931-b5411739fecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功部署到/tmp/tmp324x57mo/deploy_lib.tar\n"
     ]
    }
   ],
   "source": [
    "from tvm import rpc, relay\n",
    "from tvm.contrib import utils\n",
    "\n",
    "# 連線\n",
    "remote = rpc.connect(\"0.tcp.jp.ngrok.io\", 11685)\n",
    "\n",
    "# 將編譯好的模型傳輸至目標設備\n",
    "temp = utils.tempdir()\n",
    "lib_fname = temp.relpath(\"deploy_lib.tar\")\n",
    "lib.export_library(lib_fname)\n",
    "remote.upload(lib_fname)\n",
    "\n",
    "# 在目標設備上加載模型\n",
    "remote_lib = remote.load_module(\"deploy_lib.tar\")\n",
    "print(f'成功部署到{lib_fname}')\n",
    "del remote\n",
    "del remote_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fab456-0ef3-4e06-bf5f-c5400c24318d",
   "metadata": {},
   "source": [
    "## 6. 連接目標設備並執行推論\n",
    "- 在開發機器上連接到目標設備的 RPC Server，並加載已編譯的模型。\n",
    "- 設置輸入數據並執行推論。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc5d145-6b84-4147-9d0c-9f0696a79fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論結果： [[6.0250437e-05 2.8771785e-01 7.1222192e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import rpc, relay\n",
    "from tvm.contrib import utils, graph_executor\n",
    "\n",
    "remote = rpc.connect(\"0.tcp.jp.ngrok.io\", 11685)\n",
    "# 在目標設備上加載模型\n",
    "remote_lib = remote.load_module(\"/tmp/tmp324x57mo/deploy_lib.tar\")\n",
    "\n",
    "# 創建 graph executor，使用目標設備的 CPU\n",
    "module = graph_executor.GraphModule(remote_lib[\"default\"](remote.cpu()))\n",
    "\n",
    "# 設置輸入數據\n",
    "# 準備輸入資料\n",
    "input_data = np.array([[6.3, 3.3, 6.0, 2.5]], dtype=np.float32)\n",
    "# input_data = tvm.nd.array(input_array, device=remote.cpu())  # 輸入的數據\n",
    "module.set_input(\"float_input\", input_data)\n",
    "\n",
    "# 執行推論\n",
    "module.run()\n",
    "\n",
    "# 取得輸出\n",
    "output = module.get_output(0).asnumpy()\n",
    "print(\"推論結果：\", output)\n",
    "\n",
    "# 釋放資源\n",
    "del module\n",
    "del remote_lib\n",
    "del remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b164ba34-152a-4a12-ad39-b8f16cbec810",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lib0.o\n",
      "devc.o\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf deploy_lib.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c099e-8df7-4ea0-9e1f-e664f8df3d06",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- [如何在TVM 中使用RPC 進行交叉編譯和遠端設備執行](https://tvm.hyper.ai/docs/tutorial/rpc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15659c-9f9b-42f2-993e-0be09717de42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
